#!/usr/bin/env python3
"""AI Daily Dashboard generator with Traditional Chinese summaries."""

from __future__ import annotations

import json
import re
from dataclasses import dataclass
from datetime import datetime, timedelta, timezone
from email.utils import parsedate_to_datetime
from html import escape, unescape
from pathlib import Path
from typing import Any, Dict, List
from urllib.parse import urlencode
from urllib.request import Request, urlopen

WORKSPACE = Path("/home/ubuntu/.openclaw/workspace/ai-dashboard")
DASHBOARD_MD = WORKSPACE / "DASHBOARD.md"
DASHBOARD_HTML = WORKSPACE / "index.html"
RAG_DATA_FILE = WORKSPACE / "rag_data" / "rag_data.json"
LOG_FILE = WORKSPACE / "update.log"

ATOM_NS = "{http://www.w3.org/2005/Atom}"
USER_AGENT = "Mozilla/5.0 (AI-Dashboard-Aggregator)"
TRANSLATE_ENDPOINT = "https://translate.googleapis.com/translate_a/single"
LOOKBACK_HOURS = 36
MIN_ARTICLES = 6
SUMMARY_LIMIT = 400

RSS_SOURCES = [
    {"name": "The Verge Â· AI", "url": "https://www.theverge.com/rss/ai-artificial-intelligence/index.xml"},
    {"name": "TechCrunch Â· Artificial Intelligence", "url": "https://techcrunch.com/category/artificial-intelligence/feed/"},
    {"name": "MIT Technology Review Â· AI", "url": "https://www.technologyreview.com/feed/?category_name=artificial-intelligence"},
    {"name": "Ars Technica Â· AI", "url": "https://feeds.arstechnica.com/arstechnica/technology-lab"},
    {"name": "AI Trends", "url": "https://www.aitrends.com/feed/"},
]

# ---------------------------------------------------------------------------

def log(message: str) -> None:
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    LOG_FILE.parent.mkdir(parents=True, exist_ok=True)
    with LOG_FILE.open("a", encoding="utf-8") as fh:
        fh.write(f"[{timestamp}] {message}\n")

def http_get(url: str, timeout: int = 20) -> bytes:
    req = Request(url, headers={"User-Agent": USER_AGENT})
    with urlopen(req, timeout=timeout) as resp:
        return resp.read()

def strip_html(text: str) -> str:
    text = unescape(text or "")
    text = re.sub(r"<[^>]+>", " ", text)
    text = re.sub(r"\s+", " ", text)
    return text.strip()

def node_text(element, tag: str) -> str:
    value = element.findtext(tag)
    if value:
        return value.strip()
    value = element.findtext(ATOM_NS + tag)
    if value:
        return value.strip()
    return ""

def translate_to_traditional(text: str) -> str:
    if not text:
        return ""
    params = urlencode({
        "client": "gtx",
        "sl": "auto",
        "tl": "zh-TW",
        "dt": "t",
        "q": text[:SUMMARY_LIMIT],
    })
    url = f"{TRANSLATE_ENDPOINT}?{params}"
    try:
        raw = http_get(url, timeout=15)
        data = json.loads(raw.decode("utf-8"))
        translated = "".join(segment[0] for segment in data[0])
        return translated.strip()
    except Exception as exc:
        log(f"âš ï¸ ç¿»è­¯å¤±æ•—ï¼ˆä½¿ç”¨åŸæ–‡ï¼‰ï¼š{exc}")
        return text

@dataclass
class Article:
    title: str
    link: str
    source: str
    published: datetime
    summary: str

    def to_markdown(self) -> str:
        date_str = self.published.strftime("%Y-%m-%d %H:%M %Z")
        return (
            f"- **[{self.title}]({self.link})**  _{self.source} Â· {date_str}_  \n"
            f"  {self.summary}"
        )

    def to_html(self) -> str:
        date_str = self.published.strftime("%Y-%m-%d %H:%M %Z")
        return (
            "<li>"
            f"<strong><a href=\"{escape(self.link)}\" target=\"_blank\">{escape(self.title)}</a></strong><br>"
            f"<span class=\"source\">{escape(self.source)} Â· {date_str}</span>"
            f"<p>{escape(self.summary)}</p>"
            "</li>"
        )

# ---------------------------------------------------------------------------

def parse_feed(data: bytes, source: str) -> List[Article]:
    import xml.etree.ElementTree as ET

    articles: List[Article] = []
    try:
        root = ET.fromstring(data)
    except ET.ParseError as exc:
        log(f"âŒ ç„¡æ³•è§£æ {source} RSSï¼š{exc}")
        return articles

    items = root.findall(".//item")
    if not items:
        items = root.findall(f".//{ATOM_NS}entry")

    for item in items:
        title = node_text(item, "title")
        link = node_text(item, "link")
        if not link:
            link_el = item.find("link") or item.find(ATOM_NS + "link")
            if link_el is not None:
                link = (link_el.get("href") or link_el.text or "").strip()
        pub_date_raw = node_text(item, "pubDate") or node_text(item, "updated")
        summary_raw = node_text(item, "description") or node_text(item, "summary")
        summary_clean = strip_html(summary_raw)[:SUMMARY_LIMIT]
        summary = translate_to_traditional(summary_clean)

        if not title or not link:
            continue

        try:
            pub_dt = parsedate_to_datetime(pub_date_raw)
            if pub_dt.tzinfo is None:
                pub_dt = pub_dt.replace(tzinfo=timezone.utc)
            else:
                pub_dt = pub_dt.astimezone(timezone.utc)
        except Exception:
            pub_dt = datetime.now(timezone.utc)

        articles.append(Article(title=title, link=link, source=source, published=pub_dt, summary=summary))
    return articles

def collect_news() -> List[Article]:
    cutoff = datetime.now(timezone.utc) - timedelta(hours=LOOKBACK_HOURS)
    aggregated: List[Article] = []
    for source in RSS_SOURCES:
        try:
            data = http_get(source["url"])
            parsed = parse_feed(data, source["name"])
            recent = [a for a in parsed if a.published >= cutoff]
            if not recent:
                recent = sorted(parsed, key=lambda a: a.published, reverse=True)[:2]
            aggregated.extend(recent)
            log(f"âœ… {source['name']} æŠ“åˆ° {len(recent)} å‰‡")
        except Exception as exc:
            log(f"âŒ ç„¡æ³•æŠ“å– {source['name']}ï¼š{exc}")
    aggregated.sort(key=lambda a: a.published, reverse=True)
    return aggregated

def split_sections(articles: List[Article]) -> Dict[str, List[Article]]:
    if not articles:
        return {"headlines": [], "industry": [], "highlights": []}
    return {
        "headlines": articles[:2],
        "industry": articles[2:6],
        "highlights": articles[6:8],
    }

# ---------------------------------------------------------------------------

def load_rag() -> Dict[str, Any]:
    if not RAG_DATA_FILE.exists():
        log("âš ï¸ æ‰¾ä¸åˆ° RAG è³‡æ–™ï¼Œç•¥éè©²å€å¡Š")
        return {}
    with RAG_DATA_FILE.open("r", encoding="utf-8") as fh:
        return json.load(fh)

def render_rag_markdown(rag: Dict[str, Any]) -> str:
    if not rag:
        return ""
    lines: List[str] = ["## ğŸ¤– RAG è³‡è¨Š", "", "### ğŸ“š æœ€æ–° AI Agent è«–æ–‡", ""]
    for paper in rag.get("papers", [])[:3]:
        lines.append(f"- **[{paper['title']}]({paper['url']})**  ")
        lines.append(f"  {paper.get('abstract', '').strip()}")
        lines.append("")
    lines.append("### ğŸ’» ç†±é–€é–‹æºå°ˆæ¡ˆ\n")
    for project in rag.get("projects", [])[:4]:
        lines.append(f"- **[{project['name']}]({project['url']})**  ")
        lines.append(f"  {project.get('description', '').strip()}")
        lines.append("")
    lines.append("### ğŸ¤— Hugging Face è¶¨å‹¢\n")
    for model in rag.get("models", [])[:2]:
        lines.append(f"- **[{model['name']}]({model['url']})**  ")
        lines.append(f"  {model.get('description', '').strip()}")
        lines.append("")
    return "\n".join(lines).strip()

def render_rag_html(rag: Dict[str, Any], today: str) -> str:
    if not rag:
        return ""

    def build(items: List[Dict[str, Any]], keys: tuple[str, str, str], limit: int) -> str:
        html_items = []
        for item in items[:limit]:
            title = escape(str(item.get(keys[0], "")))
            url = escape(str(item.get(keys[1], "")))
            desc = escape(str(item.get(keys[2], "")))
            html_items.append(f"<li><strong><a href=\"{url}\" target=\"_blank\">{title}</a></strong><p>{desc}</p></li>")
        return "".join(html_items)

    return f"""
            <section class=\"dashboard-section\">
                <h2>ğŸ“š AI Agent ç ”ç©¶ & RAG è³‡è¨Š</h2>
                <p class=\"date-subtitle\">æ›´æ–°ï¼š{today}</p>
                <div class=\"news-card\">
                    <h3>æœ€æ–°è«–æ–‡</h3>
                    <ul>
                        {build(rag.get('papers', []), ('title', 'url', 'abstract'), 3)}
                    </ul>
                </div>
                <div class=\"news-card\">
                    <h3>ç†±é–€é–‹æºå°ˆæ¡ˆ</h3>
                    <ul>
                        {build(rag.get('projects', []), ('name', 'url', 'description'), 4)}
                    </ul>
                </div>
                <div class=\"news-card\">
                    <h3>Hugging Face è¶¨å‹¢</h3>
                    <ul>
                        {build(rag.get('models', []), ('name', 'url', 'description'), 2)}
                    </ul>
                </div>
            </section>
        """

# ---------------------------------------------------------------------------

def render_markdown(sections: Dict[str, List[Article]], rag: Dict[str, Any]) -> str:
    now = datetime.now()
    today = now.strftime("%Y-%m-%d")
    yesterday = (now - timedelta(days=1)).strftime("%Y-%m-%d")
    updated = now.strftime("%Y-%m-%d %H:%M")

    parts: List[str] = [
        "# ğŸ¤– AI æ¯æ—¥å„€è¡¨æ¿",
        "",
        f"## ğŸ“… {today}",
        "",
        f"### ğŸ“° æ˜¨æ—¥ AI å¤§äº‹ä»¶ ({yesterday})",
        "",
        f"_æœ€å¾Œæ›´æ–°ï¼š{updated}_",
        "",
        "---",
        "",
        "## ğŸ”¥ é ­æ¢æ–°è",
        "",
    ]

    headlines = sections.get("headlines", [])
    parts.extend(a.to_markdown() for a in headlines) if headlines else parts.append("_ï¼ˆæš«ç„¡è³‡æ–™ï¼‰_")
    parts.append("")

    parts.append("## ğŸ’¼ ç”¢æ¥­å‹•æ…‹\n")
    industry = sections.get("industry", [])
    parts.extend(a.to_markdown() for a in industry) if industry else parts.append("_ï¼ˆæš«ç„¡è³‡æ–™ï¼‰_")
    parts.append("")

    parts.append("## ğŸ§  æ·±åº¦è§€é»\n")
    highlights = sections.get("highlights", [])
    parts.extend(a.to_markdown() for a in highlights) if highlights else parts.append("_ï¼ˆæš«ç„¡è³‡æ–™ï¼‰_")
    parts.append("")

    rag_block = render_rag_markdown(rag)
    if rag_block:
        parts.append(rag_block)
        parts.append("")

    parts.extend([
        "---",
        "",
        "## âš™ï¸ è¨­å®šç‹€æ…‹",
        "",
        "- âœ… å„€è¡¨æ¿è‡ªå‹•ç”Ÿæˆ",
        "- âœ… å¤šä¾†æº RSS + RAG è³‡æ–™æ•´åˆ",
        f"- ğŸ“ ä½ç½®ï¼š`{DASHBOARD_MD}`",
        "",
        "## ğŸ”„ æ›´æ–° schedule",
        "",
        "- **é »ç‡**ï¼šæ¯å¤©ä¸Šåˆ 8:00",
        "- **æ¶µè“‹**ï¼šå‰ 24~36 å°æ™‚ AI æ–°è + RAG è³‡è¨Š",
        "",
        "---",
        "",
        "*ç”±å°ç®¡å®¶ ğŸ¤– è‡ªå‹•ç”Ÿæˆ*",
    ])

    return "\n".join(parts)

def render_html(sections: Dict[str, List[Article]], rag: Dict[str, Any]) -> str:
    now = datetime.now()
    today = now.strftime("%Y-%m-%d")
    updated = now.strftime("%Y-%m-%d %H:%M")

    def render_list(items: List[Article]) -> str:
        if not items:
            return '<p class="empty">ç›®å‰æ²’æœ‰è³‡æ–™</p>'
        return "<ul>" + "".join(article.to_html() for article in items) + "</ul>"

    rag_section = render_rag_html(rag, today)

    return f"""<!DOCTYPE html>
<html lang=\"zh-TW\">
<head>
    <meta charset=\"UTF-8\">
    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">
    <title>AI æ¯æ—¥å„€è¡¨æ¿</title>
    <link rel=\"stylesheet\" href=\"style.css\">
    <link href=\"https://fonts.googleapis.com/css2?family=Noto+Sans+TC:wght@300;400;500;700&display=swap\" rel=\"stylesheet\">
</head>
<body>
    <div class=\"container\">
        <header>
            <h1>ğŸ¤– AI æ¯æ—¥å„€è¡¨æ¿</h1>
            <p class=\"subtitle\">è¿½è¹¤æœ€æ–° AI ç™¼å±• Â· æ¯æ—¥è‡ªå‹•æ›´æ–°</p>
            <div class=\"last-updated\">æœ€å¾Œæ›´æ–°ï¼š{updated}</div>
        </header>
        <main>
            <section class=\"dashboard-section\">
                <h2>ğŸ“… {today}</h2>
                <p class=\"date-subtitle\">æ˜¨æ—¥ AI å¤§äº‹ä»¶</p>
                <div class=\"news-card\">
                    <h3>ğŸ”¥ é ­æ¢æ–°è</h3>
                    {render_list(sections.get('headlines', []))}
                </div>
                <div class=\"news-card\">
                    <h3>ğŸ’¼ ç”¢æ¥­å‹•æ…‹</h3>
                    {render_list(sections.get('industry', []))}
                </div>
                <div class=\"news-card\">
                    <h3>ğŸ§  æ·±åº¦è§€é»</h3>
                    {render_list(sections.get('highlights', []))}
                </div>
            </section>
            {rag_section}
            <section class=\"automation-info\">
                <h3>âš™ï¸ è‡ªå‹•åŒ–ç‹€æ…‹</h3>
                <div class=\"status-grid\">
                    <div class=\"status-item\"><span class=\"status-icon\">âœ…</span>RSS èšåˆ</div>
                    <div class=\"status-item\"><span class=\"status-icon\">âœ…</span>RAG æ•´åˆ</div>
                    <div class=\"status-item\"><span class=\"status-icon\">âœ…</span>æ¯æ—¥ 08:00 å®šæ™‚æ›´æ–°</div>
                </div>
            </section>
        </main>
        <footer>
            <p>ç”±å°ç®¡å®¶ ğŸ¤– è‡ªå‹•ç¶­è­· â€¢ Firebird çš„ AWS é›²ç«¯ç®¡å®¶</p>
        </footer>
    </div>
</body>
</html>
"""

# ---------------------------------------------------------------------------

def main() -> None:
    log("â–¶ï¸ é–‹å§‹ç”Ÿæˆå„€è¡¨æ¿")
    articles = collect_news()
    if len(articles) < MIN_ARTICLES:
        log(f"âš ï¸ æ–‡ç« æ•¸ä¸è¶³ ({len(articles)} < {MIN_ARTICLES})ï¼Œä»ä½¿ç”¨ç¾æœ‰è³‡æ–™ç”Ÿæˆ")
    sections = split_sections(articles)
    rag = load_rag()

    DASHBOARD_MD.write_text(render_markdown(sections, rag), encoding="utf-8")
    log("ğŸ“ å·²å¯«å…¥ DASHBOARD.md")

    DASHBOARD_HTML.write_text(render_html(sections, rag), encoding="utf-8")
    log("ğŸ•¸ï¸ å·²å¯«å…¥ index.html")

    log("âœ… å„€è¡¨æ¿æ›´æ–°å®Œæˆ")
    print("Dashboard updated successfully.")


if __name__ == "__main__":
    main()
